# [2023-03-10] 전문가리뷰

---

### 서비스 소개

서비스자체가 구글 아날리틱스와 똑같다. 좋은 아이디어다.

빅데이터 서비스라는것 자체가 데이터를 수집하는 것 부터 시작이다.

여기서 인사이트를 뽑아서 보여주는 것이다.

잘 기획을 했고 기술 스택도 잘 선정했다.

### 아키텍처

Hive 에서 Spring boot로 가져오는 것에 대한 것은 쿼리를 통해 가져올 수 있다.

하지만 생각보다 많이 느리다.

수십 수만의 유저가 본다고 가정하는 것은 많이 느리고

Hive에서 쿼리를 보내서 가져오는 것이 많이 느리다.

하이브에서 정형화해서 보낸다.

하이브에서 batch를 거쳐 데이터를 만든다.

하이브에서 에어플로우에서 통계데이터를 RDBMS로 마이그레이션 해서 보내는것이 현장과 비슷하게 갈 수 있다.

서비스 자체가 빠를 필요는 없다. 상황에 따라서 설정했다.

제일 많이 쓰이는 기술 스택이다.

카프카에서 스파크 스트리밍 HDFS에 적재 → 에어플로우로 하이브에 적재

현업과 크게 다르지 않다.

### 질문4

Q. 앞서 언급한 정보를 제외하고 +@로 얻을만한 정보가 있을까요?

A. 광고 노출 시 관련 캐시정보를 활용한다. 이게 보통은 법적으로 제한된게 너무 많다. 대부분은 
가져올 수 없다. 유저 정보(private), 위치정보, 접속 기록, 보통 Journey를 볼 수 있는것이 중요한 Feature이다. 쇼핑정보도 DBMS에서 가져올 수 있다.(어떤 물품을 구매했는지 등등…)

Q. 실시간으로 표시할 필요가 있는가? 실시간으로 표현할 데이터는 무엇이 있을까요?

A. 보통 카프카를 통해서 처리하는 것은 실시간으로 가기가 힘들다. 스트리밍이어도 Fure 스트리밍이아니라 Micro Batch이다. 진짜 실시간으로 처리한다면 Flink로 처리한다. Apache Storm으로도 가능하다. 하지만 진짜 실시간으로 처리하는 경우는 서비스에서만 쓴다. 고객인사이트 데이터는 굳이 실시간까지는 필요하지 않다. 트래픽에 민감한 경우실시간에 쓰이겠지만 굳이? 이다.

어뷰저 데이터때문에 실시간으로 처리하지 않는 성향이 강하다. 현재 서비스는 실시간까진 필요하지 않을거다.

Q. 실제 기업에서는 실시간 데이터를 어떻게 저장하고 가져오는지?

A. 앞서 말한 것들이 현업과 유사하다. 데이터 웨어하우스의 개념을 가진 인프라 OLTP라와 OLAP 인프라가 있다. OLTP는 Data warehouse로, OLAP는 Data lake로 생각할 수 있다. 빅데이터 실시간은 API를 통해 유저의 광고 노출을 기록한다. 카프카에 들어온 값을 후처리한다. JSON은 트래픽이 적을 때는 상관이 없는데 많아진다면 무조건 Lagging이 걸리고 Avro와 같은 Serializer를 처리해주어야 한다. 카프카에 들어온 데이터를 웨어하우스/ 통계값을 보낸다.

Elastic search에 넣는 방식이 있다. 우리는 요새 드루이드? 에 넣는다.

Q. 데이터 엔지니어의 테크트리에 대해

A. 첫 번째는 알고리즘 테스트, 결국 신입한테 요구하는 것은 기본기이다. 가장 중요한 것은 문제 해결 능력. 입사후에 테크에 대한 사내 표준을 제공한다. 
두 번째는 지금 프로젝트 잘끝내기.

Q. 데이터 엔지니어가 출퇴근시 하는 스크립트?

A. 주기적인 Sustain을 위한 장치가 있다. 로그파일이 쌓이고 있는데 로그가 너무 많이 쌓였을 경우 메일로 Alert오도록 한다. 엔터프라이즈 레벨로 가면 모든것이 로깅이 되면 좋다. 수기로 실행하는 것보다는 모든것을 규격화하여 사용하는 것이 좋다. 모니터화면을 안꺼주게하는 암페타민

서비스를 개발하거나 프로세스를 겪거나 한건 없었다. 연구조직이었거등요~ 

쿠팡에서는 개발/서비스 프로세스, 코로나