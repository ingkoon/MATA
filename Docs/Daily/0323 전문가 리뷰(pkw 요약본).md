# 0323 전문가 리뷰

# Ground Rule
특성상 도메인에 대한 지식이 있는 사람이 주도하기 때문에 팀원이 다같이 작업하는 경우가 별로 없다. 그러니 다른 팀원들이 이 기회에 배워 가면 좋을 것임


실제 기업의 백단은 더 복잡하게 구성되어 있지만, 데이터 파이프라인만 놓고 본다면 현재 진행하는 실무에서 쓰는것과 거의 똑같은 상황이다.

싸피 내부는 물론이고 인터넷에도 자료가 드물기 때문에 사례를 잘 문서화하고 공유해서 다른 조원이나 후배 기수들과 함께 상부상조하면 좋을것같다. 따라서 프로젝트도 잘하고 있지만 ‘우리가 카프카를 쓸때 어떤식으로 사용했다.’라는걸 md로 잘 남겨주면 좋을것 같다.

# 1.유저 접속위치 질문

 로그인 세션이 생기면 세션 id가 있고, 세션이 생기면 주소 정보를 넣을 수 없다. 머신러닝의 데이터로 사용하기 위해 주소 정보를 쓰고 싶으면, 주소는 사용이 가능하지만 특정 사용자를 식별할 수 있는 id는 사용할 수 없다는 한계가 있다. 데이터가 특정될수 없게끔 해시 함수를 통해 익명화해서 처리해야 하는 부분이 있음. 서드파티 쿠키를 이용하는 법이 있고, 네이버 같은 경우에는 처음부터 사용자에게 동의를 구하며, 서드파티 쿠키를 사용하기 위해 사용자에게 동의 버튼을 누르게해 브라우저 정보를 가져오는 방법도 있다. 요즘은 브라우저 정보를 통해서도 위치 정보, 온도나 습도 같은 것도 얻을 수 있다. (이거 한번 확인해볼 것, 브라우저 api에 있다)
 네이버에서 서드파티 쿠키라는 개념을 광고업체 위주로 사용했다. 그러나 요즘 개인정보 보호법이 서드파티 쿠키를 금지하는 추세이다. 그래서 이 방법에 종말이 올것이다라는 이야기가 있고, 요즘은 다시 퍼스트 파티 쿠키를 사용하려 하고 있다. (ex 네이버에서는 네이버쿠키만 가능) 요즘 마케팅, 광고 업계에서 자회사 서비스의 누적된 데이터를 활용할 수 있는 업체들이 힘을 얻고있다.

# 2. 체류시간 정하는 기준, 방법론?



- 첫째는 세션기준, 세션을 빡빡하게 보는곳이 금융쪽인데 15초 아무행동 안 하는 사람 등등, 모든 액션들을 로그를 찍고 본다. 고객 여정을 세세하게 감시할 수 있는 것이 세션인데, 가장 큰 단점은 트래픽이 많이 몰린다. 그래서 jwt쓰는건데 고객의 여정을 관리하기 어렵다. 그래서 쓰는것이 jwt를 쓰는데 쿠키에 모든 정보를 때려박는거다. 그래서 써드파티는 커넥션에 암호화돼있지않다. 근데 요즘은 많은 트래픽을 위해 jwt를 쓰는데 이런것들때문에 개인정보가 탈취당할 수 있다. 한동안은 jwt기반의 서드파티 쿠키 방식의 저니를 선택했었다. 그런데 다시 상술한 이유로 다시 퍼스트 파티 쿠키로 하게 되면 새로운 정책이 생기지 않을까싶다. 어플리케이션 같은 경우는 os도 그렇고 어플리케이션을 시작부터 끝내는 시간까지 사용량등을 os에서 측정한다. 얼마나 사용했고 등등 모든것을 액션 바이 액션으로 어떻게든 전송받는 (ex서드파티쿠키) 방식으로 체류시간같은걸 전달받고 있다.

# 3. 하둡을 사용할때 질문

- 하둡의 용도는 기본적으로 데이터 아카이빙이다. 네이버 광고팀에서만 수집하는 데이터가 하루에 60tb이다. 그만큼 굉장히 많은 데이터가 생성되고 이런 대용량 데이터를 rdb에서 처리, 저장하는 것은 불가능하다. 그래서 보통 가공된 데이터를 다룰 때보다 raw 데이터들은 실제 로그가 많기 때문에 그런 것들은 하둡시스템에 들어가고 중간중간 가공단계에서 체크포인트들이 생성되고 그 체크포인트들도 상황에 따라 hdfs에 덤프하는경우가있다. 왜냐? 각팀이 원하는게 다를수가 있어서. tb단위의 데이터를 아카이빙 해야 할 일이 있을때 빅데이터로서의 의미가 잇고 rdb에 들어가야되는 데이터들은 모든것들이 통계가 난 데이터들이다. 그래서 기껏 해봐야 메가바이트, 기가바이트 정도의 용량이어야 rdb에서 관리가 가능하다. 아카이빙의 중요성이 뭐냐면, 서비스가 장애가 났을때 어떻게 보상을 할것이냐에 대한 고민들이있다. 예를 들어 카카오에서 불이나서 서비스 장애가 있었다. 그러면 예를 들어 택시 서비스가 3일동안 잃은 손실을 측정하는 방법은 앞서 우리가 갖고있던 데이터들을 기반으로 3일 매출을 측정하고 그걸 기반으로 보상을 하는것이다. 물론 비효율 적인 부분도 있겟지만 전문가 경험으로는, 개인적으로 옵티마이징하는걸 좋아해서 낭비도 싶은 부분도 있지만 일을 할수록 필요한것들이 각각 다르고 비즈니스적인 부분이 복잡하기 때문에 모든것을 아카이빙 해놓는것들이 좋다. rdb는 실제 서비스에 나가는 데이터들을 남아놓는다.

# 4. 막힐때 사용하는 매체, 인사이트

- 나도 어렵다. 잘정리된게 잇으면 좋은데 없다.
그래서 첫째 한글 책으로 된걸 한번 찾아본다. 근데 보통 없다. 다음에 서비스를 도입해보려고 하고 그 과정에서 docs를 많이 찾아보게 된다. docs환경이랑 실제 기업환경이 많이 다르기 때문에 그때 docs를 굉장히 많이 찾아보게된다. 그 외로 추가적인 것들을 알고싶다하면 원서까지 찾아보게된다. 매체로는 컨퍼런스가 아는게 몇개 있는데 네이버에 데뷰라는 컨퍼런스도 있고 고젝? feast 뭐시기 컨퍼런스를 통해 네트워크를 형성하고 유튜브 인도친구들이 참 착하다.

서비스의 구성이나 동작하는 방식을 일목요연하게 정리한 것이 필요한데 정말 찾아도 안 나온다.

# 5. 최근에 관심이 가는분야

## 1. 현재 mlops 업무를 하고 있는데 관심이 갔던 이유

- 데이터 사이언스를 하면서 모델을 열심히 만들었고 ‘왜 얘는 코드랑 논문이랑 다르지?’ 생각하면서 새로 논문도 작성해 보았는데, gpt모델이나 bert나올때도 그렇고 이런 대규모의 연구는 대한민국에서 하기 너무 어렵다. 모델 연구를 따라갈 방법이 없는것 같다. 일단 gpu나 컴퓨팅 자원 등의 인프라가 부족해서 연구를 하기 너무 어려운 나라다. 그렇다면 모델을 만드는게 어려우면 우리나라에서 뭘 할수 있을까 하다가 ‘모델을 서빙하는 서비스를 개발하는 쪽으로 치중하자’ 라는 생각을 했다. 그래서 고민을 많이 하다 보니, mlops라는 분야에서 열심히 공부를 하고 있다.

## 2. MLops 컨퍼런트 공유

- kubeflow라는 플랫폼이 있는데, 데이터 파이프라인부터 모델학습까지 가능하다.
이걸 쿠버네티스에 끼워넣으면 머신러닝 전반을 쿠버네티스에서 할 수 있다. 모델학습 하이퍼파라미터 튜닝, 서빙 등등 토탈솔루션을 담당하는데, 첫째로는 연구를 위한 툴을 어떻게 운영할것인가? 이었다. 지금은 쥬피터를 많이 사용하고 있음.

두 번째, 모델 학습을 어떻게 할것인가? 이건 파이토치냐 텐서플로냐 이런 고민을 하는데, 지피티는 파이토치다. 그리고 이제 서빙 부분, 추론 서빙 부분이 있다. 모델 서빙에서 트래픽이 클 때 피쳐는 엄청 많다. 그걸 어떻게 빠르게 통신할수 있을지에 대한 고민등을 하고있다. kserve, BentoML, [seldon-core](https://mlops-for-all.github.io/docs/setup-components/install-components-seldon/) 등이 있다. 이 친구들이 지원하는 가장 큰 주제가 grpc인데 얘가 http2 이다. 이걸로 통신을 하면 json이 아니라 데이터를 시리얼라이즈(직렬화) 해서 통신을 하는 프로토콜을 지원해 준다. 그래서 나중에 모델을 만드는 분들이랑 협업을 하게 된다면 ‘grpc로 통신해야 된다’는 라는 요청을 받게될것이다. 요즘 전문가분이 오픈소스에 많이 기여하고 있는게 ‘feature sotre’인데 한국에는 사용하는 경우가 거의 없다. 네이버의 전체 인프라를 다 뒤집어야 할 수도 있기 때문에, 이제 시작하는 과정에 있다. 지금 전문가분이 하고 있는 숙제 중 하나다.